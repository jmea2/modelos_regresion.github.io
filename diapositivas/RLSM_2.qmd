---
title: "Regresion Lineal Multiple"
author: "Jorge Mario Estrada Alvarez PhD. MSc. FETP"
footer:  "Bioestadistica III"
#logo: "images/imagen-cursoR.png"
editor: source
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
    chalkboard: true
execute:
  echo: true
  output: asis
  freeze: auto
cache: false
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(rio)
library(tidyverse)
library(marginaleffects)
library(knitr)
coronary <- import("datasets/coronary.rds")
```

## Objetivos de aprendizaje

Despu茅s de este modulo, se espera que los estudiantes sean capaces de:

-   Entender el concepto de **regresi贸n lineal simple** y **regresi贸n lineal m煤ltiple**
-   Realizar un an谩lisis de regresi贸n lineal simple (ajustar el modelo)
-   Realizar regresi贸n lineal m煤ltiple (ajuste con m谩s de un predictor)
-   Evaluar el **ajuste del modelo** de regresi贸n lineal (diagn贸sticos, $R^2$, residuos, supuestos)
-   Presentar e interpretar los resultados del an谩lisis de regresi贸n lineal (coeficientes, intervalos, significado)

## Conjunto de datos: *coronary.rds* {.smaller}

-   Usaremos el dataset **coronary.rds** en formato `R`.  [Descargar coronary.rds](dataset/coronary.rds)\
-   Corresponde a un **ensayo cl铆nico hipot茅tico** con informaci贸n de caracter铆sticas individuales, niveles de colesterol total y grupos de intervenci贸n.\
-   Contiene **200 observaciones** y **9 variables**:

| Variable | Descripci贸n |
|----|----|
| **id** | Identificaci贸n del sujeto |
| **cad** | Estado de enfermedad coronaria (categ贸rica: *sin CAD*, *con CAD*) |
| **sbp** | Presi贸n arterial sist贸lica (mmHg, num茅rica) |
| **dbp** | Presi贸n arterial diast贸lica (mmHg, num茅rica) |
| **chol** | Colesterol total (mmol/L, num茅rica) |
| **age** | Edad en a帽os (num茅rica) |
| **bmi** | ndice de masa corporal (num茅rica) |
| **race** | Raza (categ贸rica: malayo, chino, indio) |
| **gender** | Sexo (categ贸rica: mujer, hombre) |

## Regresi贸n Lineal Multiple {.smaller}

-   La **Regresi贸n Lineal Multiple (RLM)** modela la relaci贸n lineal entre:
    -   Una **variable dependiente num茅rica** (ej. colesterol).\
    -   **dos o m谩s predictores** (num茅ricas y categ贸ricas).

### Expresi贸n matem谩tica

$$
E(Y \mid X_1,X_2,X_3 \dots X_i) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \dots \beta_i X_i
$$

Donde:\
- $E(Y \mid X_i)$: valor esperado (predicho) (promedio) de la variable dependiente dado las $X_i$.\
- $\beta_0$: intercepto.\
- $\beta_i$: coeficientes de cada predictor $X_i$.

# Estimaci贸n de los parametros del modelo

## Estimaci贸n por M谩xima Verosimilitud (caso 1 covariable)

-   La idea central es elegir los par谩metros $\beta_i$ que **maximizan la probabilidad** de observar los datos.

### Supuestos b谩sicos

-   Los errores $\varepsilon_i$ se asumen **independientes** y distribuidos:\
    $\varepsilon_i \sim N(0, \sigma^2)$

-   Entonces:\
    $$
    Y_i \sim N(\beta_0 + \beta_1 X_i, \, \sigma^2)
    $$

## Funci贸n de verosimilitud {.smaller}

$$
L(\beta_0, \beta_1,\dots \beta_p \sigma^2 \mid Y) 
= \prod_{i=1}^n 
\frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(Y_i - \beta_0 - \beta_1 X_{i1} - \dots \beta_p X_{ip})^2}{2\sigma^2} \right)
$$

## Estimadores MLE

$$
\hat{\beta}_j : \text{ solucionan } 
\sum_{i=1}^n X_{ik} Y_i = \sum_{j=0}^p \hat{\beta}_j \sum_{i=1}^n X_{ik}X_{ij},
\quad k=0,\ldots,p.
$$

### Varianza del error

$$
\hat{\sigma}^2_{ML} = \frac{1}{n} \sum_{i=1}^n 
\left( Y_i - \hat{\beta}_0 - \hat{\beta}_1 X_{i1} - \cdots - \hat{\beta}_p X_{ip} \right)^2.
$$

### Errores est谩ndar

$$
SE(\hat{\beta}_j) = 
\sqrt{\hat{\sigma}^2 \cdot c_{jj}}, \quad j=0,\ldots,p,
$$

## Modelo: Colesterol en funcion de la Presi贸n arterial sistolica

**Objetivo:** Se requiere predecir los valores de colesterol de pacientes cuando se conoce su presion arterial sistolica, presencia de enfermedad cardiaca, sexo, BMI y raza

-   Asumimos que la relaci贸n entre las variables es lineal. (deberia validarse en el bivariado)

-   Segun el modelo lineal planteado seria:

$$\mu_{chol} = \beta_0 + \beta_1 \times sbp + \beta_2 \times gender + \beta_3 \times bmi + \beta_4 \times race$$

Que valores asumen $\beta_i$

## Ajuste del modelo

```{r,results='hide'}
modelo_multiple <- lm(data = coronary, formula = chol~sbp+gender+bmi+race)
summary(modelo_multiple)
```

![](rml.png){width="150"}

## 驴el modelo es adecuado? {.smaller}

### Prueba F

`F-statistic: 10.54 on 5 and 194 DF,  p-value: 5.728e-09`: el modelo es significativo, con la `las variables` se permite explicar el `colesterol`.

### Error estandar residual

`Residual standard error: 19.1` para saber que tan grande es: Tasa de error de predicci贸n:

```{r}
summary(modelo_multiple)$sigma/mean(coronary$chol)*100
```

Una tasas de error de 17.1%

### Coeficiente de determinacion $R^2$ y $R^2-ajustado$

```{r}
summary(modelo_multiple)$r.squared
```

```{r}
summary(modelo_multiple)$adj.r.squared
```

El ajuste es regular, se explica el 19.3% de la variabilidad del Colesterol

## Estimaci贸n de coeficientes {.smaller}

```{r, results='asis'}
summary(modelo_multiple)$coefficients %>% 
  kable()
```

Modelo completo: $$\mu_{chol} = 97.66 + 0.29 \times sbp + 1.49 \times gender -0.83 \times bmi + 6.59 \times chino + 12.25 \times hindu$$

## Interpretaci贸n de Coeficientes

-   $\beta_0$ Representa la respuesta media cuando todos los predictores valen cero. Hay que ser cautos con su interpretaci贸n, porque su valor puede no tener un significado pr谩ctico.

-   $\beta_1$: las pendientes (o gradientes). Representan el cambio en la respuesta media por unidad de aumento en la variable explicativa asociada, cuando todos los otros predictores se mantienen constantes. Es decir, nos dicen en qu茅 medida cada variable explicativa afecta a la variable respuesta si aislamos los efectos de todos los dem谩s predictores.

$$\mu_{chol} = 97.66 + 0.29 \times sbp + 1.49 \times gender -0.83 \times bmi + 6.59 \times chino + 12.25 \times hindu$$

## Predicciones con el modelo e inferencia

Un poblaci贸n de sujetos tiene `sbp`$= 120$, `gender` $=$ `Mujer`, `bmi` $= 23$ `race` $=$ `hindu`

```{r}
predictions(modelo_multiple, newdata = data.frame(sbp = 120, gender = "Mujer",bmi = 23,
                                                 race = "Hindu")) %>% 
  select(2:9) %>% 
   kable(digits = 2,align = "c","html")
```

```{r}
predictions(modelo_multiple, newdata = data.frame(sbp = 180, gender = "Mujer",bmi = 23,
                                                 race = "Hindu")) %>% 
  select(2:9) %>% 
   kable(digits = 2,align = "c","html")
```

## Inferencia: Coeficientes {.smaller}

```{r}
summary(modelo_multiple)$coefficients %>% 
  kable()
```

```{r}
confint(modelo_multiple) %>% kable()
```

## Comparaci贸n de modelo: Seleccion de variables

-   Se hace necesario evaluar la contribucion de las variables que ingresan al modelo, ya que un modelo mas *parsimonioso* (menos variables) y explicando la misma variabilidad es mas deseable.

-   Comparar un modelo full vs modelo reducido

### Criterio de informacion de Akaike AIC {.smaller}

```{r, results='hide'}
modelo_multiple_rdc <- lm(formula = chol ~ sbp + bmi + race, data = coronary)
```

```{r}
AIC(modelo_multiple, modelo_multiple_rdc) %>% kable()
```

## Comparaci贸n de modelo: Seleccion de variables

### Prueba F Parcial

La prueba F parcial eval煤a si el modelo completo es significativamente mejor que el modelo reducido (Si la variable excluida contribuye significativamente)

```{r}
anova(modelo_multiple, modelo_multiple_rdc) %>% kable()
```

##  {.smaller}

```{r}
summary(modelo_multiple_rdc)$coefficients%>% kable()
```

```{r}
summary(modelo_multiple)$coefficients%>% kable()
```

## En modelos predictivos

En comparaciones multiples se hace dificil probar todos los posible modelos, sin embargo un algortimo automatico puede ayudarnos a reducir el trabajo sin perder el criterio epidemiologico:

```{r, results='hide'}
final <- step(modelo_multiple,direction = "backward")
```

```{r}
summary(final)$coefficients %>% kable()
```

## Diagn贸stico: Supuestos

Determinar si el modelo representa adecuadamente a los datos.

-   Supuestos b谩sicos (acr贸nimo **LINE**):

-   **L de Linealidad**: Los valores de (Y) se pueden expresar como una funci贸n lineal de la variable (X).

-   **I de Independencia**:Los valores de (Y) (o los errores/residuos) son independientes entre s铆.

-   **N de Normalidad**:Para cualquier valor fijo de (X), los valores de (Y) (o los errores/residuos) se distribuyen normalmente.

-   **E de Equitatividad (Homoscedasticidad)**: La variaci贸n de los valores de (Y) (o los errores/residuos) alrededor de la l铆nea de regresi贸n es constante.

## Diagnostico con graficos (Verificaci贸n de supuestos)

::::: columns
::: {.column width="50%"}
![](d1.png){width="500"}
:::

::: {.column width="50%"}
![](d111.png){width="500"}
:::
:::::

Linealidad y homocedasticidad: sin patrones Causas: modelo no lineal, falta de variables explicativas, interacci贸n.

## Diagnostico con graficos (Verificaci贸n de supuestos)

::::: columns
::: {.column width="50%"}
![](d2.png){width="500"}
:::

::: {.column width="50%"}
![](d222.png){width="500"}
:::
:::::

Falta de Normalidad: Otro modelos lineales generalizados

## Diagnostico con graficos (Verificaci贸n de supuestos)

::::: columns
::: {.column width="50%"}
![](d3.png){width="500"}
:::

::: {.column width="50%"}
![](d333.png){width="500"}
:::
:::::

Homogeneidad de la varianza: Transformaciones

## Diagnostico con graficos (Verificaci贸n de supuestos)

::::: columns
::: {.column width="50%"}
![](d4.png){width="500"}
:::

::: {.column width="50%"}
![](d444.png){width="500"}
:::
:::::

Identificar valores inusuales e influyentes: Transformaciones.

# Confusi贸n e Interacci贸n en Regresion Lineal Multiple
